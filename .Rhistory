group_by(CO) %>%
summarise(m_diff = mean(procedural)) %>%
arrange(m_diff)
m_diff_con <- scores_diff %>%
group_by(CO) %>%
summarise(m_diff = mean(conceptual)) %>%
arrange(m_diff)
m_diff_pro
m_diff_con
# create a summary of means
m_diff_pro <- scores_diff %>%
group_by(IT) %>%
summarise(m_diff = mean(procedural)) %>%
arrange(m_diff)
m_diff_con <- scores_diff %>%
group_by(IT) %>%
summarise(m_diff = mean(conceptual)) %>%
arrange(m_diff)
m_diff_pro
m_diff_con
t.test(scores_diff[scores_diff[,"IT"] == 0,][,"conceptual"], scores_diff[scores_diff[,"IT"] == 1,][,"conceptual"])
install.packages("ggplot2")
library(ggplot2)
dat <- scores_diff %>%
select(group, procedural)
ggplot()
dat
dat
ggplot(dat)
ggplot(dat) +
aes(x = group, y = procedural, color = group) +
geom_jitter() +
theme(legend.position = "none")
dat <- scores_diff %>%
select(group, conceptual)
ggplot(dat) +
aes(x = group, y = conceptuall, color = group) +
geom_jitter() +
theme(legend.position = "none")
ggplot(dat) +
aes(x = group, y = conceptual, color = group) +
geom_jitter() +
theme(legend.position = "none")
dat <- scores_diff %>%
select(group, procedural)
res_aov <- aov(procedural ~ group,
data = dat
)
hist(res_aov$residuals)
shapiro.test(res_aov$residuals)
boxplot(procedural ~ group,
data = dat
)
summary(res_aov)
# ANOVA analysis
res_aov_pro <- aov(procedural ~ group,
data = scores_diff
)
res_aov_con <- aov(conceptual ~ group,
data = scores_diff
)
summary(res_aov_con)
res_aov_con <- aov(conceptual ~ IT,
data = scores_diff
)
summary(res_aov_con)
boxplot(conceptual ~ IT,
data = dat
)
boxplot(conceptual ~ IT,
data = scores_diff
)
boxplot(conceptual ~ group,
data = scores_diff
)
## ANOVA analysis ##
# pretest scores comparable?
res_aov_pro_pre <- aov(procedural ~ group,
data = scores
)
## ANOVA analysis ##
# pretest scores comparable?
res_aov_pro_pre <- aov(pre_procedural ~ group,
data = scores
)
summary(res_aov_pro_pre)
res_aov_con_pre <- aov(pre_conceptual ~ group,
data = scores
)
summary(res_aov_con_pre)
## ANOVA analysis ##
# pretest scores comparable?
res_aov_pro_pre <- aov(pre_procedural ~ group,
data = scores
)
summary(res_aov_pro_pre)
# ctt analysis
# todo: wiw mach ich das mit den dimensionen?
# erste idee: prozedurale, konzeotuelle, pre- und posttest jeweils getrennt, also vier verschiedene Analysen
# zweites Argument: mp
data_pre_pro = data[,1:12]
View(data_pre_pro)
ctt_results = tam.ctt(data_pre_pro, mp)
# ctt analysis
# todo: wiw mach ich das mit den dimensionen?
# erste idee: prozedurale, konzeotuelle, pre- und posttest jeweils getrennt, also vier verschiedene Analysen
# zweites Argument: mp
data_pre_pro = as.dataframe(data[,1:12])
# ctt analysis
# todo: wiw mach ich das mit den dimensionen?
# erste idee: prozedurale, konzeotuelle, pre- und posttest jeweils getrennt, also vier verschiedene Analysen
# zweites Argument: mp
data_pre_pro = as.data.frame(data[,1:12])
ctt_results = tam.ctt(data_pre_pro, mp)
# ctt analysis
# todo: wiw mach ich das mit den dimensionen?
# erste idee: prozedurale, konzeotuelle, pre- und posttest jeweils getrennt, also vier verschiedene Analysen
# zweites Argument: mp
data[is.na(data)] <- 9
View(data)
ctt_results = tam.ctt(data_pre_pro, mp)
data_pre_pro = as.data.frame(data[,1:12])
ctt_results = tam.ctt(data_pre_pro, mp)
View(data_pre_pro)
# get data
data <- read_csv2("C:/Users/Sina-/Dropbox/Lehrstuhl/Diss/Pilotierung/Auswertung/R/data_pilot_study_4dimensions_withCodes.csv", show_col_types = FALSE)
# get vector with person codes and remove codes from data matrix
pid <- data[,1]
data <- data[,colnames(data)!="code"]
# workaround, to be fixed properly (model cannot work with no correct answers for K2 in pretest)
data[48, 28] = 1
data_pre_pro = as.data.frame(data[,1:12])
data_pre_pro[is.na(data_pre_pro)] <- 1
ctt_results = tam.ctt(data_pre_pro, mp)
mp
data_pre_pro = as.data.frame(data[,1:12])
data_pre_pro = as.data.frame(data[,1:12])
ctt_results = tam.ctt(data_pre_pro, mp.EAP.Dim1)
ctt_results = tam.ctt(data_pre_pro, mp$EAP.Dim1)
summary(ctt_results)
ctt_results$rpb.PV
ctt_results$rpb.WLE
data_pre_pro = as.data.frame(data[,1:12])
View(data_pre_pro)
ctt_results = tam.ctt(data_pre_pro, mp$EAP.Dim1)
ctt_results$rpb.WLE
ctt_results
library(readr)
library(TAM)
library(tidyverse)
library(ggplot2)
# get data
data <- read_csv2("C:/Users/Sina-/Dropbox/Lehrstuhl/Diss/Pilotierung/Auswertung/R/data_pilot_study_4dimensions_withCodes.csv", show_col_types = FALSE)
# get vector with person codes and remove codes from data matrix
pid <- data[,1]
data <- data[,colnames(data)!="code"]
# workaround, to be fixed properly (model cannot work with no correct answers for K2 in pretest)
data[48, 28] = 1
# create Q matrix (which items are procedural, which items are conceptual, which items are pre-test, which items are post_test)
c1 = c(rep(1,12), rep(0,36))
c2 = c(rep(0,12), rep(1,12), rep(0,24))
c3 = c(rep(0,24), rep(1,12), rep(0,12))
c4 = c(rep(0,36), rep(1,12))
Q <- cbind(c1, c2, c3, c4)
# item difficulties vector from previous item difficulty analysis
helper <- c(0.50189960, -0.22386191,  1.13192395, -0.57766624,  0.66262545,  0.06177244,  1.14419493, -0.06011864, -0.17107972, -0.55505357,  2.08488869, -1.78601545,  0.42900665, -1.32039032,  2.13347273,  2.58106289, -0.64429442,  1.19238419, -0.70788167,  0.01978021, 0.74237838,  1.34027718, -0.88423183, -0.14950996)
# item difficulty is the same in pretest and posttest
helper2 = c(helper[1:12],helper[1:12],helper[13:24],helper[13:24])
# model expects array with 2 columns, first indicates index of item
diffics = cbind(1:48, helper2)
# analysis of items
mod <- TAM::tam.mml( resp=data, Q=Q,  xsi.fixed = diffics, pid=pid, control=list(snodes=2000) )
mp <- mod$person
fitting = (tam.fit(mod))$itemfit
min(fitting$Infit_t)
max(fitting$Infit_t)
#### manual analysis of person parameters of groups ####
# extract person scores
scores <- cbind(mp$EAP.Dim1, mp$EAP.Dim2,mp$EAP.Dim3,mp$EAP.Dim4)
rownames(scores) = mp$pid
scores <- as.data.frame(scores)
# write treatment group of each participant and type (NCO/CO, NIT/IT)
# first, add columns with zeros
n = dim(pid)[1]
scores <- cbind(scores, rep(0,n), rep(0,n), rep(0,n))
# write group number and types into last three columns of matrix
for (i in 1:n) {
group = as.integer(substr(rownames(scores)[i], 2, 2))
scores[i, 5] = group
if (group == 1 || group == 2) {
scores[i, 6] = 0 # NCO
} else {
scores[i, 6] = 1 # CO
}
if (group == 1 || group == 3) {
scores[i, 7] = 0 # NIT
} else {
scores[i, 7] = 1 # IT
}
}
# name columns appropriately
colnames(scores) <- c("pre_procedural", "post_procedural", "pre_conceptual", "post_conceptual", "group", "CO", "IT")
# get difference scores (pretest to posttest) of participants: TODO: macht das sinn, kann man die differnezen gut interpretieren?
diff_scores_pro = scores[,"post_procedural"] - scores[,"pre_procedural"]
diff_scores_con = scores[,"post_conceptual"] - scores[,"pre_conceptual"]
scores_diff = cbind(diff_scores_pro, diff_scores_con, scores[,"group"], scores[,"CO"], scores[,"IT"])
colnames(scores_diff) = c("procedural", "conceptual", "group", "CO", "IT")
rownames(scores_diff) = mp$pid
scores_diff <- as.data.frame(scores_diff)
# save diff scores per group
diff1 <- scores_diff[scores_diff[, "group"] == 1,]
diff2 <- scores_diff[scores_diff[, "group"] == 2,]
diff3 <- scores_diff[scores_diff[, "group"] == 3,]
diff4 <- scores_diff[scores_diff[, "group"] == 4,]
diff1
boxplot(diff1[,"procedural"])
boxplot(diff1[,"procedural"], diff2[,"procedural"])
boxplot(diff1[,"procedural"], diff2[,"procedural"], diff3[,"procedural"], diff4[,"procedural"])
res_aov_pro <- aov(procedural ~ group,
data = scores_diff
)
report(res_aov_pro)
library(report)
report(res_aov_pro)
library(readr)
# get data
data <- read_csv2("C:/Users/Sina-/Dropbox/Lehrstuhl/Diss/Pilotierung/Auswertung/R/data_pilot_study.csv", show_col_types = FALSE)
# get different groups of participants
group1 <- data[which(data$group==1),]
group2 <- data[which(data$group==2),]
group3 <- data[which(data$group==3),]
group4 <- data[which(data$group==4),]
group_not_interactions <- data[which(data$interaction==0),] # groups 1 + 3
group_interactions <- data[which(data$interaction==1),] # groups 2 + 4
group_not_compr_oriented <- data[which(data$compr_oriented==0),] # groups 1 + 2
group_compr_oriented <- data[which(data$compr_oriented==1),] # groups 3 + 4
data
View(data)
mean(data[,"pre_score_procedural"])
data[;"pre_score_procedural"]
data[,"pre_score_procedural"]
mean(data[,"pre_score_procedural"])
data <- as.dataframe(data)
data <- as.data.frame(data)
mean(data[,"pre_score_procedural"])
mean(data[,"pre_score_conceptual"])
mean(data[,"gain_conceptual"])
mean(data[,"gain_procedural"])
group1 <- data[which(data$group==1),]
group2 <- data[which(data$group==2),]
group3 <- data[which(data$group==3),]
group4 <- data[which(data$group==4),]
boxplot(group1[,"gain_procedural"], group2[,"gain_procedural"], group3[,"gain_procedural"], group4[,"gain_procedural"])
boxplot(group1[,"gain_procedural"], group2[,"gain_procedural"], group3[,"gain_procedural"], group4[,"gain_procedural"], ylab="Zuwachs prozedurale Items")
boxplot(group1[,"gain_procedural"], group2[,"gain_procedural"], group3[,"gain_procedural"], group4[,"gain_procedural"], ylab="Zuwachs prozedurale Items", names=c("Gruppe 1", "Gruppe 2", "Gruppe 3", "Gruppe 4"))
boxplot(group1[,"gain_conceptual"], group2[,"gain_conceptual"], group3[,"gain_conceptual"], group4[,"gain_conceptual"], ylab="Zuwachs konzeptuelle Items", names=c("Gruppe 1", "Gruppe 2", "Gruppe 3", "Gruppe 4"))
library(readr)
library(TAM)
library(tidyverse)
library(ggplot2)
library(report)
# get data
data <- read_csv2("C:/Users/Sina-/Dropbox/Lehrstuhl/Diss/Pilotierung/Auswertung/R/data_pilot_study_4dimensions_withCodes.csv", show_col_types = FALSE)
# get vector with person codes and remove codes from data matrix
pid <- data[,1]
data <- data[,colnames(data)!="code"]
# workaround, to be fixed properly (model cannot work with no correct answers for K2 in pretest)
data[48, 28] = 1
# create Q matrix (which items are procedural, which items are conceptual, which items are pre-test, which items are post_test)
c1 = c(rep(1,12), rep(0,36))
c2 = c(rep(0,12), rep(1,12), rep(0,24))
c3 = c(rep(0,24), rep(1,12), rep(0,12))
c4 = c(rep(0,36), rep(1,12))
Q <- cbind(c1, c2, c3, c4)
# item difficulties vector from previous item difficulty analysis
helper <- c(0.50189960, -0.22386191,  1.13192395, -0.57766624,  0.66262545,  0.06177244,  1.14419493, -0.06011864, -0.17107972, -0.55505357,  2.08488869, -1.78601545,  0.42900665, -1.32039032,  2.13347273,  2.58106289, -0.64429442,  1.19238419, -0.70788167,  0.01978021, 0.74237838,  1.34027718, -0.88423183, -0.14950996)
# item difficulty is the same in pretest and posttest
helper2 = c(helper[1:12],helper[1:12],helper[13:24],helper[13:24])
# model expects array with 2 columns, first indicates index of item
diffics = cbind(1:48, helper2)
# analysis of items
mod <- TAM::tam.mml( resp=data, Q=Q,  xsi.fixed = diffics, pid=pid, control=list(snodes=2000) )
mp <- mod$person
fitting = (tam.fit(mod))$itemfit
min(fitting$Infit_t)
max(fitting$Infit_t)
#### manual analysis of person parameters of groups ####
# extract person scores
scores <- cbind(mp$EAP.Dim1, mp$EAP.Dim2,mp$EAP.Dim3,mp$EAP.Dim4)
rownames(scores) = mp$pid
scores <- as.data.frame(scores)
# write treatment group of each participant and type (NCO/CO, NIT/IT)
# first, add columns with zeros
n = dim(pid)[1]
scores <- cbind(scores, rep(0,n), rep(0,n), rep(0,n))
# write group number and types into last three columns of matrix
for (i in 1:n) {
group = as.integer(substr(rownames(scores)[i], 2, 2))
scores[i, 5] = group
if (group == 1 || group == 2) {
scores[i, 6] = 0 # NCO
} else {
scores[i, 6] = 1 # CO
}
if (group == 1 || group == 3) {
scores[i, 7] = 0 # NIT
} else {
scores[i, 7] = 1 # IT
}
}
# name columns appropriately
colnames(scores) <- c("pre_procedural", "post_procedural", "pre_conceptual", "post_conceptual", "group", "CO", "IT")
# get difference scores (pretest to posttest) of participants: TODO: macht das sinn, kann man die differnezen gut interpretieren?
diff_scores_pro = scores[,"post_procedural"] - scores[,"pre_procedural"]
diff_scores_con = scores[,"post_conceptual"] - scores[,"pre_conceptual"]
scores_diff = cbind(diff_scores_pro, diff_scores_con, scores[,"group"], scores[,"CO"], scores[,"IT"])
colnames(scores_diff) = c("procedural", "conceptual", "group", "CO", "IT")
rownames(scores_diff) = mp$pid
scores_diff <- as.data.frame(scores_diff)
# save diff scores per group
diff1 <- scores_diff[scores_diff[, "group"] == 1,]
diff2 <- scores_diff[scores_diff[, "group"] == 2,]
diff3 <- scores_diff[scores_diff[, "group"] == 3,]
diff4 <- scores_diff[scores_diff[, "group"] == 4,]
# create a summary of means
m_diff_pro <- scores_diff %>%
group_by(IT) %>%
summarise(m_diff = mean(procedural)) %>%
arrange(m_diff)
sd_diff_pro <- scores_diff %>%
group_by(IT) %>%
summarise(sd_diff = sd(procedural)) %>%
arrange(sd_diff)
m_diff_con <- scores_diff %>%
group_by(CO) %>%
summarise(m_diff = mean(conceptual)) %>%
arrange(m_diff)
sd_diff_con <- scores_diff %>%
group_by(CO) %>%
summarise(sd_diff = sd(conceptual)) %>%
arrange(sd_diff)
m_pro_pre <- scores %>%
group_by(IT) %>%
summarise(m_pro = mean(pre_procedural)) %>%
arrange(m_pro)
m_pro_con <- scores %>%
group_by(group) %>%
summarise(m_con = mean(pre_conceptual)) %>%
arrange(m_con)
# check if data is distributed normally for whole data set
hist(scores_diff[,"procedural"])
hist(scores_diff[,"conceptual"])
ks.test(scores_diff[,"procedural"], "pnorm", mean=mean(scores_diff[,"procedural"]), sd = sd(scores_diff[,"procedural"]))
ks.test(scores_diff[,"conceptual"], "pnorm", mean=mean(scores_diff[,"conceptual"]), sd = sd(scores_diff[,"conceptual"]))
# check for normal distribution within treatment groups
ks.test(diff1[,1], "pnorm", mean=mean(diff1[,1]), sd = sd(diff1[,1]))
ks.test(diff1[,2], "pnorm", mean=mean(diff1[,2]), sd = sd(diff1[,2]))
ks.test(diff2[,1], "pnorm", mean=mean(diff2[,1]), sd = sd(diff2[,1]))
ks.test(diff2[,2], "pnorm", mean=mean(diff2[,2]), sd = sd(diff2[,2]))
ks.test(diff3[,1], "pnorm", mean=mean(diff3[,1]), sd = sd(diff3[,1]))
ks.test(diff3[,2], "pnorm", mean=mean(diff3[,2]), sd = sd(diff3[,2]))
ks.test(diff4[,1], "pnorm", mean=mean(diff4[,1]), sd = sd(diff4[,1]))
ks.test(diff4[,2], "pnorm", mean=mean(diff4[,2]), sd = sd(diff4[,2]))
#dat <- scores_diff %>%
#  select(group, procedural)
#ggplot(dat) +
#  aes(x = group, y = conceptual, color = group) +
#  geom_jitter() +
#  theme(legend.position = "none")
## ANOVA analysis ##
# pretest scores comparable?
res_aov_pro_pre <- aov(pre_procedural ~ group,
data = scores
)
summary(res_aov_pro_pre)
report(res_aov_pro_pre)
res_aov_pro_pre_1 <- aov(pre_procedural ~ CO,
data = scores
)
summary(res_aov_pro_pre_1)
report(res_aov_pro_pre_1)
res_aov_pro_pre_2 <- aov(pre_procedural ~ IT,
data = scores
)
summary(res_aov_pro_pre_2)
report(res_aov_pro_pre_2)
res_aov_con_pre <- aov(pre_conceptual ~ group,
data = scores
)
summary(res_aov_con_pre)
# results of groups
res_aov_pro <- aov(procedural ~ IT,
data = scores_diff
)
res_aov_con <- aov(conceptual ~ IT,
data = scores_diff
)
# check if data is normally distributed
#shapiro.test(res_aov$residuals)
boxplot(conceptual ~ IT,
data = scores_diff,
names = c("No interactive tasks", "Interactive tasks")
)
boxplot(conceptual ~ CO,
data = scores_diff,
names = c("Not comprehension-oriented", "Comprehension-oriented")
)
# ctt analysis
# todo: wiw mach ich das mit den dimensionen?
# erste idee: prozedurale, konzeotuelle, pre- und posttest jeweils getrennt, also vier verschiedene Analysen
# zweites Argument: mp
data_pre_pro = as.data.frame(data[,1:12])
#data_pre_pro[is.na(data_pre_pro)] <- 1
ctt_results = tam.ctt(data_pre_pro, mp$EAP.Dim1)
ctt_results$rpb.WLE
boxplot(procedural ~ CO,
data = scores_diff,
names = c("NVO", "VO"),
ylab="Zuwachs prozedurale Items"
)
boxplot(conceptual ~ CO,
data = scores_diff,
names = c("NVO", "VO"),
ylab="Zuwachs prozedurale Items"
)
boxplot(conceptual ~ CO,
data = scores_diff,
names = c("NVO", "VO"),
ylab="Zuwachs konzeptuelle Items"
)
boxplot(procedural ~ CO,
data = scores_diff,
names = c("Gruppe NVO", "Gruppe VO"),
ylab="Zuwachs prozedurale Items"
)
boxplot(conceptual ~ CO,
data = scores_diff,
names = c("Gruppe NVO", "Gruppe VO"),
ylab="Zuwachs konzeptuelle Items"
)
res_aov_pro <- aov(procedural ~ CO,
data = scores_diff
)
report(res_aov_pro)
res_aov_con <- aov(conceptual ~ CO,
data = scores_diff
)
report(res_aov_con)
boxplot(procedural ~ IT,
data = scores_diff,
names = c("Gruppe NIA", "Gruppe IA"),
ylab="Zuwachs prozedurale Items"
)
boxplot(conceptual ~ IT,
data = scores_diff,
names = c("Gruppe NIA", "Gruppe IA"),
ylab="Zuwachs konzeptuelle Items"
)
# results of groups
res_aov_pro <- aov(procedural ~ IT,
data = scores_diff
)
res_aov_con <- aov(conceptual ~ IT,
data = scores_diff
)
report(res_aov_pro)
report(res_aov_con)
tam.fit(mod)
data
data_pre_pro = as.data.frame(data[,1:12])
ctt_results = tam.ctt(data_pre_pro, mp$EAP.Dim1)
ctt_results$rpb.WLE
res <- ctt_results$rpb.WLE
min(abs(res))
max(res)
data_post_pro = as.data.frame(data[,13:24])
data_pre_con = as.data.frame(data[,25:36])
data_post_con = as.data.frame(data[,37:48])
ctt_results = tam.ctt(data_post_pro, mp$EAP.Dim1)
res <- ctt_results$rpb.WLE
min(abs(res))
max(res)
res
ctt_pre_pro = tam.ctt(data_pre_pro, mp$EAP.Dim1)
ctt_post_pro = tam.ctt(data_post_pro, mp$EAP.Dim1)
ctt_pre_con = tam.ctt(data_pre_con, mp$EAP.Dim1)
ctt_post_con = tam.ctt(data_post_con, mp$EAP.Dim1)
pbc_pre_pro <- ctt_pre_pro$rpb.WLE
pbc_post_pro <- ctt_post_pro$rpb.WLE
pbc_pre_con <- ctt_pre_con$rpb.WLE
pbc_post_con <- ctt_post_con$rpb.WLE
min(abs(pbc_pre_con))
pbc_pre_pro
pbc_post_pro
pbc_pre_pro
pbc_pre_con
pbc_post_con
tam.fit(mod)
x = 3
x
x + 5
x
x = x + 5
x
source("../transformation_0_1/transform_codes_to_0_1.R")
source("./transformation_0_1/transform_codes_to_0_1.R")
..
setwd("..")
getwd()
setwd("C:/Users/Sina-/Dropbox/Lehrstuhl/Diss/Auswertung/R")
source("transformation_0_1/transform_codes_to_0_1.R")
transform_codes("test")
